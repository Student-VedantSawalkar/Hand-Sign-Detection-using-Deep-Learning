# âœ‹ğŸ¤– Hand-Sign-Detection-using-Deep-Learning

**Hand-Sign-Detection-using-Deep-Learning** is a project designed to assist the deaf community by translating hand signs into alphabet letters. Using computer vision and deep learning, this system bridges communication gaps and enhances accessibility. ğŸ§â€â™‚ï¸ğŸ’¡

---

## ğŸŒŸ Features
- ğŸ“· **Real-Time Hand Detection**: Detects hands using `cvzone.HandTrackingModule`.
- ğŸ–¼ï¸ **Image Preprocessing**: Captures, resizes, and adjusts aspect ratios for accurate recognition.
- ğŸ§  **Deep Learning Integration**: Utilizes a pre-trained Keras model to classify hand gestures into letters.
- ğŸ”¤ **Live Feedback**: Displays the detected letter directly on the video stream.

---

## ğŸš€ How It Works
1. **Data Collection**:
   - Use the `data_collection.py` script to capture hand gesture images and save them for training. ğŸ“¸
2. **Real-Time Detection**:
   - The `test.py` script processes webcam input and identifies the corresponding letter for the detected hand sign. ğŸ¥

---

## ğŸ“‚ Project Structure
- **`data_collection.py`**: Script for collecting and preprocessing hand gesture images.
- **`test.py`**: Script for real-time prediction of hand signs using the deep learning model.
- **`model/`**: Directory containing the pre-trained `keras_model.h5` and `labels.txt`.

---

## ğŸ› ï¸ Dependencies
- OpenCV ğŸ¥
- cvzone âœ¨
- NumPy â•
- TensorFlow/Keras ğŸ§ 

